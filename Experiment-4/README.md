# Experiment 4: Ensemble Techniques and Decision Tree Models

This experiment focuses on building **ensemble models**, implementing **stacked classifiers**, and exploring different **variants of decision tree models**.

## Dataset

* Source: [Breast Cancer Wisconsin (Diagnostic) Dataset â€“ UCI Repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)
* Description: This dataset contains features computed from digitized images of breast mass fine needle aspirates (FNA). The task is to classify tumors as **malignant** or **benign**.

## Models Implemented

The following models were implemented as Jupyter notebooks:

1. **Decision Tree Classifier**
2. **Ensemble Variants of Decision Trees**
   * Bagging Classifier
   * Random Forest
   * AdaBoost
   * Gradient Boosting
   * Extreme Gradient Boosting (XGBoost)
3. **Stacked Ensemble**

## Steps Involved

1. Data preprocessing and feature scaling.
2. Training baseline decision tree classifier.
3. Implementing ensemble methods (bagging, boosting, random forests, stacking).
4. Evaluating performance using **Accuracy, Precision, Recall, F1-Score, ROC-AUC**.
